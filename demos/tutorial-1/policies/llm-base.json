{
  "constraints": {
    "parameters": {
      "tool:*/complete": {
        "max_tokens": {
          "max": 4000
        },
        "model": [
          "gpt-3.5-turbo-instruct",
          "davinci-002",
          "babbage-002"
        ],
        "temperature": {
          "max": 2.0,
          "min": 0
        }
      },
      "tool:*/embed": {
        "model": [
          "text-embedding-ada-002",
          "text-embedding-3-small",
          "text-embedding-3-large"
        ]
      },
      "tool:*/generate": {
        "frequency_penalty": {
          "max": 2.0,
          "min": -2.0
        },
        "max_tokens": {
          "max": 4000
        },
        "model": [
          "gpt-3.5-turbo",
          "gpt-4"
        ],
        "presence_penalty": {
          "max": 2.0,
          "min": -2.0
        },
        "temperature": {
          "max": 2.0,
          "min": 0
        },
        "top_p": {
          "max": 1.0,
          "min": 0
        }
      }
    },
    "rate_limit": 100
  },
  "denied_resources": [
    "*.secret",
    "*.password",
    "*.pem",
    "*.token",
    "*.key"
  ],
  "description": "Base policy for LLM services with standard parameter constraints",
  "policy_id": "llm-base",
  "resources": [
    "tool:openai-service/generate",
    "tool:openai-service/complete",
    "tool:openai-service/embed"
  ],
  "scope": "global",
  "version": "1.0"
}